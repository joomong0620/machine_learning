{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 회귀 평가\n",
    "\n",
    "\n",
    "**회귀 평가지표**\n",
    "<table border=\"1\" cellpadding=\"5\" cellspacing=\"0\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>평가 지표</th>\n",
    "            <th>설명</th>\n",
    "            <th>LaTeX 수식</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td><strong>평균 제곱 오차 (MSE)</strong></td>\n",
    "            <td>예측 값과 실제 값의 차이를 제곱하여 평균을 낸 값입니다.</td>\n",
    "            <td>$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><strong>평균 절대 오차 (MAE)</strong></td>\n",
    "            <td>예측 값과 실제 값의 차이의 절대값을 평균한 값입니다.</td>\n",
    "            <td>$$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><strong>루트 평균 제곱 오차 (RMSE)</strong></td>\n",
    "            <td>평균 제곱 오차의 제곱근으로, 실제 오차의 크기와 같은 단위를 가집니다. 큰 오차에 대해 더 가중치를 부여하므로 MAE 대비 크다.</td>\n",
    "            <td>\n",
    "            $$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "            $$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><strong>평균 제곱 로그 오차 (MSLE)</strong></td>\n",
    "            <td>실제 값과 예측 값의 로그 차이를 제곱하여 평균을 낸 값입니다.</td>\n",
    "            <td>$$\\text{MSLE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\log(y_i + 1) - \\log(\\hat{y}_i + 1) \\right)^2$$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><strong>루트 평균 제곱 로그 오차 (RMSLE)</strong></td>\n",
    "            <td>MSLE의 제곱근으로, 로그 스케일에서의 예측 정확도를 측정합니다.</td>\n",
    "            <td>$$\n",
    "            RMSLE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\left( \\log(y_i + 1) - \\log(\\hat{y}_i + 1) \\right)^2}$$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><strong>결정 계수 (R-squared, $R^2$)<strong></td>\n",
    "            <td>모델이 데이터의 변동성을 얼마나 설명하는지를 나타냅니다.</td>\n",
    "            <td>$$R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>조정된 결정 계수 (Adjusted $R^2$)</td>\n",
    "            <td>독립 변수의 개수를 고려하여 조정한 결정 계수입니다.</td>\n",
    "            <td>$$\\text{Adjusted } R^2 = 1 - \\frac{(1-R^2)(n-1)}{n-p-1}$$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>설명 분산 점수 (Explained Variance)</td>\n",
    "            <td>예측이 실제 데이터를 얼마나 잘 설명하는지를 나타냅니다.</td>\n",
    "            <td>$$\\text{Explained Variance} = 1 - \\frac{\\text{Var}(y - \\hat{y})}{\\text{Var}(y)}$$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>평균 절대 백분율 오차 (MAPE)</td>\n",
    "            <td>예측 값과 실제 값의 차이를 실제 값으로 나눈 백분율의 절대값을 평균한 값입니다.</td>\n",
    "            <td>$$\\text{MAPE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right| \\times 100$$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>최대 절대 오차 (Max Error)</td>\n",
    "            <td>가장 큰 오차의 절대값을 측정합니다.</td>\n",
    "            <td>$$\\text{Max Error} = \\max(|y_i - \\hat{y}_i|)$$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Huber Loss</td>\n",
    "            <td>MSE와 MAE의 장점을 결합한 손실 함수입니다.</td>\n",
    "            <td>$$L_\\delta(y, \\hat{y}) = \\begin{cases} \\frac{1}{2}(y_i - \\hat{y}_i)^2, & \\text{if } |y_i - \\hat{y}_i| \\le \\delta \\\\ \\delta(|y_i - \\hat{y}_i| - \\frac{1}{2}\\delta), & \\text{otherwise} \\end{cases}$$ </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>로그 코사인 이탈 (Log-Cosh Loss)</td>\n",
    "            <td>로그 하이퍼볼릭 코사인 함수의 값을 손실로 사용합니다.</td>\n",
    "            <td>$$\\text{Log-Cosh Loss} = \\sum_{i=1}^{n} \\log(\\cosh(\\hat{y}_i - y_i))$$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>대수 평균 제곱 오차 (Log-MSE)</td>\n",
    "            <td>예측 값의 로그와 실제 값의 로그 간의 차이를 제곱하여 평균을 낸 값입니다.</td>\n",
    "            <td>$$\\text{Log-MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (\\log(y_i + 1) - \\log(\\hat{y}_i + 1))^2$$</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n"
   ],
   "id": "e18b0e4caf5e5f34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:23:47.070966Z",
     "start_time": "2025-12-04T05:23:47.066252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "id": "41dd92ff12e68ea7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:36:40.697133Z",
     "start_time": "2025-12-04T05:36:40.693565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 실제값\n",
    "y_true = np.array([3, 0.5, 2, 7])\n",
    "\n",
    "# 예측값\n",
    "y_pred = np.array([2.5, 0.0, 2, 50])\n"
   ],
   "id": "5b2a2845dc938a79",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:23:54.870357Z",
     "start_time": "2025-12-04T05:23:54.861303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 평균제곱오차 MSE - Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mse"
   ],
   "id": "aaf3d9f54cb4f67f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462.375"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:23:55.960786Z",
     "start_time": "2025-12-04T05:23:55.954056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 평균절대오차 MAE - Mean Absolute Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mae"
   ],
   "id": "450fb10da225222b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:23:57.285562Z",
     "start_time": "2025-12-04T05:23:57.277705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 루트평균제곱오차 RMSE - Root Mean Squared Error # 0에 가까울수록 좋은 것\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "rmse"
   ],
   "id": "68cc9f7fa751d92d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.502906780247176"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:24:02.833289Z",
     "start_time": "2025-12-04T05:24:02.824897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# R^2 결정계수 # 1에 가까울수록 좋은 것\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "r2"
   ],
   "id": "72c1e5baf957e7d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-78.76280323450135"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:26:24.039483Z",
     "start_time": "2025-12-04T05:26:24.035810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Huber Loss\n",
    "# - 지정한 delta 값보다 오차가 작으면 MSE, 크면 MAE 적용"
   ],
   "id": "5696f3a7041facc2",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T05:37:17.263302Z",
     "start_time": "2025-12-04T05:37:17.255808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def huber_loss(y_true, y_pred, delta=1.0):\n",
    "   error = y_true - y_pred\n",
    "   is_small_error = np.abs(error) <= delta\n",
    "\n",
    "   squared_loss = 0.5 * (error ** 2)\n",
    "   linear_loss = delta * (np.abs(error) - 0.5 * delta)\n",
    "\n",
    "    # np.where(조건, 값1, 값2) : 삼항연산자\n",
    "   return np.where(is_small_error, squared_loss, linear_loss).mean()\n",
    "\n",
    "\n",
    "huber_loss(y_true, y_pred)"
   ],
   "id": "2c36648509fe0d6e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(10.6875)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
