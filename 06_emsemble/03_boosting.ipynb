{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 03.Boosting계열\n",
    "Boosting은 **여러 개의 약한 모델(Weak Learner 주로 얕은 결정 트리)** 을 **순차적으로 학습**시켜 **이전 모델의 오류를 보완**해나가는 **강한 예측기(Strong Predicter)** 를 사용하는 앙상블 기법이다.\n",
    "\n",
    "\n",
    "- 약한 모델(예: 작은 깊이의 결정 트리)을 순차적으로 학습\n",
    "- 이전 모델의 **오류(잔차)** 를 다음 모델이 보정(이전 모델이 틀린 샘플에 더 높은 가중치)\n",
    "- 각 모델의 예측을 **가중합**하여 최종 예측을 수행\n",
    "- 학습 방식: **순차적** / **오류 중심 개선**\n",
    "- 사용 모델: 주로 **깊이가 얕은 결정 트리**\n",
    "- 최적화 방식: **경사하강법(Gradient Descent)**\n",
    "\n",
    "\n",
    "| 장점 | 단점 |\n",
    "|------|------|\n",
    "| 과적합에 비교적 강함 | 트리를 **순차적으로 학습**하여 속도가 느림 |\n",
    "| 일반적으로 랜덤 포레스트보다 성능이 더 높음 | 병렬 처리 어려움 (순차 학습 구조) |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Boosting 알고리즘 발전 단계**\n",
    "- Boosting은 **오차 보정 방식의 순차적 학습 구조**로 앙상블을 구성\n",
    "- **Gradient Boosting**은 경사하강법으로 트리를 추가하며 오차를 줄임\n",
    "- **HistGradientBoosting**은 학습 속도와 메모리 효율성을 높인 개선된 버전 (노드분할 효율성을 위해 연속형 특성에 대한 binning 처리)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**손실 함수 및 학습 설정**\n",
    "\n",
    "\n",
    "| 항목 | 설명 |\n",
    "|------|------|\n",
    "| **분류** | 로지스틱 손실 함수(log loss) 사용 |\n",
    "| **회귀** | 평균제곱오차(MSE) 사용 |\n",
    "| **학습률 (learning_rate)** | 한 번에 추가되는 트리의 영향력을 조절 |\n",
    "| **subsample** | 훈련 세트 중 일부만 사용하면 확률적 경사하강법(SGD)처럼 작동 |\n",
    "\n",
    "\n",
    "> ⚠ `subsample < 1.0` → **일부 데이터로 학습하여 일반화 성능 향상 가능**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**주요 알고리즘 및 클래스**\n",
    "\n",
    "\n",
    "알고리즘 | 등장년도 | 핵심 특징\n",
    "--- | --- | ---\n",
    "AdaBoost | 1996 | 가중치를 이용해 오답 샘플을 강조\n",
    "Gradient Boosting (GBM) | 1999 | 잔차(오차)를 줄이도록 새 모델 학습\n",
    "XGBoost | 2014 | 정규화 + 병렬처리 최적화\n",
    "LightGBM | 2017 | 히스토그램 기반 + Leaf-wise 트리\n",
    "CatBoost | 2017 | 범주형 자동 처리 + 빠른 속도\n",
    "HistGradientBoosting (scikit-learn) | 2019~ | LightGBM과 유사한 히스토그램 기반 구현\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**히스토그램 기반 그레디언트 부스팅이란?**\n",
    "\n",
    "\n",
    "히스토그램 기반 그레디언트 부스팅은 기존 GBM의 **느린 학습 속도** 문제를 개선한 방식이다.\n",
    "\n",
    "\n",
    "- 연속 데이터를 **구간(binning)** 으로 나눠 계산량을 줄임\n",
    "- 속도는 빠르면서도 일반 GBM에 가까운 예측 성능 유지\n",
    "- 대용량 데이터 처리에 적합\n",
    "\n",
    "\n"
   ],
   "id": "981d66bac68f2b0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:36.432234Z",
     "start_time": "2025-12-22T04:01:36.426266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from statistics import LinearRegression\n",
    "from turtledemo.sorting_animate import disable_keys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import VotingClassifier, GradientBoostingRegressor, HistGradientBoostingClassifier, \\\n",
    "    HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import root_mean_squared_error, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor"
   ],
   "id": "5e275e89caed172c",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 01. SimpleGradientBoostingClassifier  구현\n",
    "- 잔차를 학습하는 GradientBoosting 분류기를 직접 구현"
   ],
   "id": "47af9685583a3bf1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:36.492854Z",
     "start_time": "2025-12-22T04:01:36.473508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "# 데이터 분리\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "print(X_train[:3])\n",
    "print(y_train[:3])"
   ],
   "id": "1579b6dce5160482",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (455,)\n",
      "(114, 30) (114,)\n",
      "[[1.032e+01 1.635e+01 6.531e+01 3.249e+02 9.434e-02 4.994e-02 1.012e-02\n",
      "  5.495e-03 1.885e-01 6.201e-02 2.104e-01 9.670e-01 1.356e+00 1.297e+01\n",
      "  7.086e-03 7.247e-03 1.012e-02 5.495e-03 1.560e-02 2.606e-03 1.125e+01\n",
      "  2.177e+01 7.112e+01 3.849e+02 1.285e-01 8.842e-02 4.384e-02 2.381e-02\n",
      "  2.681e-01 7.399e-02]\n",
      " [2.018e+01 1.954e+01 1.338e+02 1.250e+03 1.133e-01 1.489e-01 2.133e-01\n",
      "  1.259e-01 1.724e-01 6.053e-02 4.331e-01 1.001e+00 3.008e+00 5.249e+01\n",
      "  9.087e-03 2.715e-02 5.546e-02 1.910e-02 2.451e-02 4.005e-03 2.203e+01\n",
      "  2.507e+01 1.460e+02 1.479e+03 1.665e-01 2.942e-01 5.308e-01 2.173e-01\n",
      "  3.032e-01 8.075e-02]\n",
      " [1.066e+01 1.515e+01 6.749e+01 3.496e+02 8.792e-02 4.302e-02 0.000e+00\n",
      "  0.000e+00 1.928e-01 5.975e-02 3.309e-01 1.925e+00 2.155e+00 2.198e+01\n",
      "  8.713e-03 1.017e-02 0.000e+00 0.000e+00 3.265e-02 1.002e-03 1.154e+01\n",
      "  1.920e+01 7.320e+01 4.083e+02 1.076e-01 6.791e-02 0.000e+00 0.000e+00\n",
      "  2.710e-01 6.164e-02]]\n",
      "[1 0 1]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:36.544866Z",
     "start_time": "2025-12-22T04:01:36.538032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 이진 분류\n",
    " # - sigmoid(z) : 숫자값을 인자로 받아 확률값 반환\n",
    " # - log_odds(p) : 확률값을 인자로 받아 log(숫자값 z)로 반환\n",
    "\n",
    " # 초기값\n",
    "y_pred  = np.mean(y_train)\n",
    "print('y_pred', y_pred) # 양성클래스 확률값\n",
    "\n",
    "# 로그오즈 계산 :  입력(p: 확률) -> 출력(z : 로그오즈)\n",
    "log_odds = lambda p: np.log(p/(1-p))\n",
    "z = log_odds(y_pred)\n",
    "print('z=', z)\n",
    "\n",
    "# 시그모이드 계산 : 입력 (z: 로그 오즈) -> 출력(p: 확률)\n",
    "sigmoid = lambda z:1 / (1+np.exp(-z))\n",
    "p = sigmoid(z)\n",
    "print('p=', p)"
   ],
   "id": "d486fd8acf22ef9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred 0.6263736263736264\n",
      "z= 0.5166907432183888\n",
      "p= 0.6263736263736264\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:37.575345Z",
     "start_time": "2025-12-22T04:01:36.597513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class SimpleGradientBoostingClassifier:\n",
    "    def __init__(self, n_estimators=100, lr=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.lr = lr\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "        self.trees = [] # 약학습기를 관리할 리스트\n",
    "        self._inital_log_odds = 0 #로그오즈 초기값\n",
    "\n",
    "    def log_odds(self, p):\n",
    "        \"\"\"p(확률)을 입력 받아, z(로그오즈)를 반환하는 함수)\"\"\"\n",
    "        return np.log(p/(1-p))\n",
    "\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        \"\"\"z(로그오즈)을 입력 받아, p(확률)를 반환하는 함수)\"\"\"\n",
    "        return 1/(1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"모델 학습 함수\"\"\"\n",
    "        #부스팅은 기존의 모델이랑 새로운것을 더해야하기 때문에 초기로그오즈값이 필요하다.\n",
    "\n",
    "        # 초기 로그오즈값 설정 (y 평균값)\n",
    "        y_mean = np.mean(y) # 확률값, 꼭 평균값일 필요는 없는데 손실을 최소화 해줘서 보통 사용한다.\n",
    "        self.initial_log_odds = self.log_odds(y_mean) # 확률값 -> 로그오즈\n",
    "\n",
    "        y_pred_log_odds = np.full_like(y, self.initial_log_odds, dtype = np.float64)\n",
    "        #print('y_pred_log_odds', y_pred_log_odds)\n",
    "\n",
    "        # 반복적으로 약학습기(회귀예측기)를 순차적으로 학습 : 이전 오차를 학습\n",
    "        for _ in range(self.n_estimators):\n",
    "            # 오차를 계산하기 위하여\n",
    "            # 로그오즈값(z) -> 확률값(p) 변환 : 왜 ? 오차를 구하기 위해서\n",
    "            y_pred_proba = self.sigmoid(y_pred_log_odds)\n",
    "                                # 확률값변환 여기서\n",
    "\n",
    "            # 잔차(오차) 계산\n",
    "            residuals = y - y_pred_proba\n",
    "\n",
    "            # 잔차에 대한 학습\n",
    "            dt_reg = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            dt_reg.fit(X, residuals) # 이전 오차에 대한 것을 학습하기 때문에 -> 그러면 어떻게 되냐? 오차를 보고 얼마나 보정을 해야하는 지 알 수 있음\n",
    "\n",
    "\n",
    "            # 현재 예측값으로 로그오즈값 갱신\n",
    "            y_pred = dt_reg.predict(X) # 보정량 예측한 값\n",
    "            y_pred_log_odds -= self.lr * y_pred # 보정량을 조금씩 쪼개서 적용시킨다.\n",
    "                                # 잔차에 대해서 학습을 했으면 얼마나 보정해야할지 보정량이 나올 것이고\n",
    "                                # 보정량을 몇 퍼센트 고정할 지 조금씩\n",
    "            # 약학습기 관리\n",
    "            self.trees.append(dt_reg) # 잔차가 계속 줄어드는 방식으로 반복된다.\n",
    "\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"모델 예측을 위한 확률값 계산 함수\"\"\"\n",
    "\n",
    "        # 초기 로그오즈 설정\n",
    "        y_pred_log_odds = np.full((X.shape[0],), self.initial_log_odds,\n",
    "                                  dtype = np.float64)\n",
    "\n",
    "        # 학습된 약학습기의 예측 결과\n",
    "        for tree in self.trees: # 잔차를 학습한 회귀 트리 반복\n",
    "            y_pred_log_odds += self.lr * tree.predict(X) # 이미 잔차 방향으로 정해져있기 때문에 +를 해준다. (!= 위에서 fit 할 때 (오차 반대방향으로 간다. 손실을 줄이기 위해서))\n",
    "\n",
    "        # 로그오즈값을 확률값으로 변환해서 반환\n",
    "        return self.sigmoid(y_pred_log_odds) # 양성클래스의 확률값만 반환\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"모델 예측 함수\"\"\"\n",
    "        return (self.predict_proba(X) >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "sgb_clf = SimpleGradientBoostingClassifier()\n",
    "sgb_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 평가\n",
    "y_pred = sgb_clf.predict(X_train)\n",
    "print(\"Train Accuracy :\", accuracy_score(y_train, y_pred))\n",
    "\n",
    "\n",
    "y_pred = sgb_clf.predict(X_test)\n",
    "print(\"Test Accuracy :\", accuracy_score(y_test, y_pred))"
   ],
   "id": "2c6eb05951b9458",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9736263736263736\n",
      "Test Accuracy : 0.9385964912280702\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:38.580760Z",
     "start_time": "2025-12-22T04:01:37.608536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class SimpleGradientBoostingClassifier :\n",
    "\n",
    "    def __init__(self, n_estimators=100, lr=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.lr = lr\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "        self.trees = [] # 약학습기를 관리할 리스트\n",
    "        self.initial_log_odds = 0 # 로그오즈 초기값\n",
    "\n",
    "    def log_odds(self, p):\n",
    "        \"\"\" p(확률)을 입력 받아, z(로그오즈)를 반환하는 함수 \"\"\"\n",
    "        return np.log(p / (1 - p))\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        \"\"\" z(로그오즈)을 입력 받아, p(확률)를 반환하는 함수 \"\"\"\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" 모델 학습 함수 \"\"\"\n",
    "\n",
    "        # 초기 로그오즈값 설정 (y 평균값)\n",
    "        y_mean = np.mean(y) # 확률값\n",
    "\n",
    "        self.initial_log_odds = self.log_odds(y_mean) # 확률값 -> 로그오즈\n",
    "\n",
    "        y_pred_log_odds = np.full_like(y, self.initial_log_odds, dtype=np.float64)\n",
    "        # print('y_pred_log_odds = ', y_pred_log_odds)\n",
    "\n",
    "        # 반복적으로 약학습기(회귀예측기)를 순차적으로 학습 : 이전 오차를 학습\n",
    "        for _ in range(self.n_estimators):\n",
    "\n",
    "            # 오차를 계산하기 위하여\n",
    "            # 로그오즈값(z) -> 확률값(p) 변환\n",
    "            y_pred_proba = self.sigmoid(y_pred_log_odds)\n",
    "\n",
    "            # 잔차(오차) 계산 : (정답 - 예측확률)\n",
    "            residuals = y - y_pred_proba\n",
    "            #         = 1 - 0.3 => 0.7   -> p가 너무 낮으니 \"z(로그오즈)를 올려서\" p를 더 키워야 한다\n",
    "            #         = 0 - 0.3 => -0.3  -> p가 너무 높으니 \"z(로그오즈)를 내려서\" p를 더 줄여야 한다\n",
    "\n",
    "\n",
    "            # 잔차(보정량) 학습: X가 들어왔을 때 residual(= z를 얼마나/어느 방향으로 움직일지)을 예측하도록 학습\n",
    "            dt_reg = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            dt_reg.fit(X, residuals) # -> 입력 X가 들어왔을 때 residual 값(보정량)이 얼마가 나와야 하는지 학습\n",
    "\n",
    "            # 현재 예측값으로 로그오즈값 갱신\n",
    "            y_pred = dt_reg.predict(X) # 보정량 예측한 값 (+면 z증가 -> p증가, -면 z감소 -> p감소)\n",
    "            y_pred_log_odds += self.lr * y_pred\n",
    "\n",
    "            # 약학습기 관리\n",
    "            self.trees.append(dt_reg)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\" 모델 예측을 위한 확률값 계산 함수 \"\"\"\n",
    "\n",
    "        # 초기 로그오즈 설정\n",
    "        y_pred_log_odds = np.full( (X.shape[0],), self.initial_log_odds, dtype=np.float64 )\n",
    "\n",
    "        # 학습된 약학습기의 예측 결과\n",
    "        for tree in self.trees:\n",
    "            y_pred_log_odds += self.lr * tree.predict(X)\n",
    "\n",
    "        # 로그오즈값을 확률값으로 변환해서 반환\n",
    "        return self.sigmoid(y_pred_log_odds) # 양성클래스 확률값만 반환\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" 모델 예측 함수 \"\"\"\n",
    "        return (self.predict_proba(X) >= 0.5).astype(int)\n",
    "\n",
    "sgb_clf = SimpleGradientBoostingClassifier()\n",
    "sgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# 평가\n",
    "y_pred = sgb_clf.predict(X_train)\n",
    "print(\"Train Accuracy : \", accuracy_score(y_train, y_pred))\n",
    "\n",
    "y_pred = sgb_clf.predict(X_test)\n",
    "print(\"Test Accuracy : \", accuracy_score(y_test, y_pred))\n"
   ],
   "id": "4fcf8c969da3149d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.9934065934065934\n",
      "Test Accuracy :  0.9298245614035088\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 02. GradientBoostingClassifier",
   "id": "9c405160cd224406"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:39.363555Z",
     "start_time": "2025-12-22T04:01:38.616762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 이진 분류 : 유방암 진단\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=42, max_depth=3)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb_clf.predict(X_train)\n",
    "print(\"Train Accuracy :\", accuracy_score(y_train, y_pred))\n",
    "\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "print(\"Test Accuracy :\", accuracy_score(y_test, y_pred))"
   ],
   "id": "282cf3485ed8e8e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 1.0\n",
      "Test Accuracy : 0.956140350877193\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:39.416297Z",
     "start_time": "2025-12-22T04:01:39.403833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 다중분류\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "\n",
    "# 타겟 클래스 0 1 2\n",
    "print(np.unique(y, return_counts=True))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "id": "c1795c0709e854bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([59, 71, 48]))\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:39.927024Z",
     "start_time": "2025-12-22T04:01:39.471411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 모델 학습\n",
    "gb_clf = GradientBoostingClassifier(random_state=42, max_depth=3)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = gb_clf.predict(X_train)\n",
    "print(\"Train Accuracy :\", accuracy_score(y_train, y_pred))\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "print(\"Test Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# classification_report 클래스별 예측성능\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "cb534ecd227d0412",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 1.0\n",
      "Test Accuracy : 0.9074074074074074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93        19\n",
      "           1       0.90      0.90      0.90        21\n",
      "           2       1.00      0.79      0.88        14\n",
      "\n",
      "    accuracy                           0.91        54\n",
      "   macro avg       0.92      0.90      0.90        54\n",
      "weighted avg       0.91      0.91      0.91        54\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 03.HistGradientBoostingClassifier\n",
    "\n",
    "\n",
    "| 항목                     | 설명                                                                                               |\n",
    "| ---------------------- |--------------------------------------------------------------------------------------------------|\n",
    "| **모델 종류**              | `HistGradientBoostingClassifier` (분류)<br>`HistGradientBoostingRegressor` (회귀)                    |\n",
    "| **핵심 개념**              | Gradient Boosting 기반의 앙상블 모델이며, **히스토그램 기반 분할 기법**으로 대규모 데이터 처리에 최적화됨                            |\n",
    "| **피처 처리 방식**           | 연속형 특성을 **최대 256개 구간(bin)** 으로 구간화하여 분할 후보를 줄이고 속도 향상                                            |\n",
    "| **결측치 처리**             | 자동 처리 (별도 전처리 불필요)                                                                               |\n",
    "| **범주형 처리**             | **별도 인코딩 없이 직접 처리 가능**                                                                           |\n",
    "| **성능 특징**              | - 기존 Gradient Boosting보다 **속도와 메모리 효율** 우수<br>- **수십만 개 이상**의 데이터에 적합<br>- **기본 설정만으로도 안정적인 성능** |\n",
    "| **영향을 받은 모델**          | Microsoft의 LightGBM                                                                              |\n",
    "| **Scikit-learn 정식 도입** | v1.0부터 experimental에서 정식 API로 변경됨                                                                |\n",
    "\n",
    "\n",
    "**장점**\n",
    "\n",
    "\n",
    "* 대규모 정형 데이터에 매우 빠르고 효율적\n",
    "* 범주형과 결측치 처리를 자동으로 지원\n",
    "* Early Stopping 등 과적합 방지 기능 내장\n",
    "\n",
    "\n",
    "**주의사항**\n",
    "\n",
    "\n",
    "* 앙상블 특성상 **개별 예측 해석 어려움**\n",
    "* 과적합 가능성 존재 → 적절한 `regularization` 필요\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**하이퍼 파라미터 (기존 GradientBoosting 클래스와 차이)**\n",
    "\n",
    "\n",
    "<table border=\"1\" cellspacing=\"0\" cellpadding=\"5\" style=\"border-collapse: collapse; width: 100%;\">\n",
    " <thead>\n",
    "   <tr style=\"background-color: #f2f2f2;\">\n",
    "     <th>공통 하이퍼파라미터</th>\n",
    "     <th>설명</th>\n",
    "   </tr>\n",
    " </thead>\n",
    " <tbody>\n",
    "   <tr>\n",
    "     <td>n_estimators</td>\n",
    "     <td>부스팅 단계의 수 (기본값: 100)</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "     <td>learning_rate</td>\n",
    "     <td>학습률 (기본값: 0.1)</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "     <td>max_depth</td>\n",
    "     <td>각 트리의 최대 깊이</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "     <td>min_samples_split</td>\n",
    "     <td>내부 노드를 분할하기 위한 최소 샘플 수</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "     <td>min_samples_leaf</td>\n",
    "     <td>리프 노드에 있어야 하는 최소 샘플 수</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "     <td>subsample</td>\n",
    "     <td>각 단계에서 사용할 샘플의 비율</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "     <td>loss</td>\n",
    "     <td>손실 함수</td>\n",
    "   </tr>\n",
    " </tbody>\n",
    " <thead>\n",
    "   <tr style=\"background-color: #ffeb99;\">\n",
    "     <th>HistGradientBoosting 추가 하이퍼파라미터</th>\n",
    "     <th>설명</th>\n",
    "   </tr>\n",
    " </thead>\n",
    " <tbody>\n",
    "   <tr style=\"background-color: #fff9e6;\">\n",
    "     <td>max_bins</td>\n",
    "     <td>각 feature를 이산화할 때 사용할 최대 bin의 수 (기본값: 255)</td>\n",
    "   </tr>\n",
    "   <tr style=\"background-color: #fff9e6;\">\n",
    "     <td>max_leaf_nodes</td>\n",
    "     <td>트리의 최대 리프 노드 수</td>\n",
    "   </tr>\n",
    "   <tr style=\"background-color: #fff9e6;\">\n",
    "     <td>l2_regularization</td>\n",
    "     <td>모델의 복잡도를 제어하기 위한 L2 정규화 계수</td>\n",
    "   </tr>\n",
    "   <tr style=\"background-color: #fff9e6;\">\n",
    "     <td>early_stopping</td>\n",
    "     <td>과적합을 방지하기 위해 조기 종료를 사용할지 여부</td>\n",
    "   </tr>\n",
    "   <tr style=\"background-color: #fff9e6;\">\n",
    "     <td>scoring</td>\n",
    "     <td>조기 종료를 위한 평가지표 (예: 'loss', 'accuracy')</td>\n",
    "   </tr>\n",
    " </tbody>\n",
    "</table>\n"
   ],
   "id": "4c414c65c7687300"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:39.967820Z",
     "start_time": "2025-12-22T04:01:39.950627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ],
   "id": "baf4e062b07af67e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30) (398,)\n",
      "(171, 30) (171,)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:40.711234Z",
     "start_time": "2025-12-22T04:01:40.112827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb_clf = HistGradientBoostingClassifier(\n",
    "    random_state=42,\n",
    "    max_iter=5000, # 약학습기 개수(n_estimators 같은 역할)\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.2,# 20%를 검증용 데이터로 사용\n",
    "    n_iter_no_change=10, # 진전이 없으면 조기 종료 해줘\n",
    "    verbose=2 # 얘는 2번으로 해야 이터레이션마다 보여줌\n",
    "\n",
    ")\n",
    "\n",
    "results = cross_validate(hgb_clf, X_train, y_train, n_jobs= -1, return_train_score=True)\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n",
    "\n",
    "print('Train score: ', results_df['train_score'].mean())\n",
    "print('Test score: ', results_df['test_score'].mean())\n",
    "# 점수차이도 크지 않고 점수도 높고, 충분히 일반화가 됐다.\n",
    "# 저거 5000번 다 돌은 게 아님, 10번 참았다가 진전이 없으면 멈춤\n"
   ],
   "id": "78c1f7dfbb4035c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9899469647680448\n",
      "Test score:  0.957373417721519\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:40.997120Z",
     "start_time": "2025-12-22T04:01:40.718241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 직접 학습\n",
    "hgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# 평가\n",
    "print('Train Accuracy: ', accuracy_score(y_train, hgb_clf.predict(X_train)))\n",
    "print('Test Accuracy:', accuracy_score(y_test, hgb_clf.predict(X_test)))\n",
    "\n",
    "# val_loss : 검증용 점수 / 아까 0.2 쓴 거\n",
    "# 점수가 0.11268보다 낮은게 10번 중에 안나와서 멈춘것!!!!!\n"
   ],
   "id": "9b99fb33545c81e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.000 GB of training data: 0.028 s\n",
      "Binning 0.000 GB of validation data: 0.001 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/5000] 1 tree, 7 leaves, max depth = 5, train loss: 0.57625, val loss: 0.59085, in 0.003s\n",
      "[2/5000] 1 tree, 9 leaves, max depth = 5, train loss: 0.50937, val loss: 0.53483, in 0.003s\n",
      "[3/5000] 1 tree, 14 leaves, max depth = 8, train loss: 0.45473, val loss: 0.48839, in 0.004s\n",
      "[4/5000] 1 tree, 14 leaves, max depth = 8, train loss: 0.40868, val loss: 0.45073, in 0.003s\n",
      "[5/5000] 1 tree, 15 leaves, max depth = 9, train loss: 0.36997, val loss: 0.41855, in 0.003s\n",
      "[6/5000] 1 tree, 15 leaves, max depth = 9, train loss: 0.33656, val loss: 0.38540, in 0.003s\n",
      "[7/5000] 1 tree, 14 leaves, max depth = 8, train loss: 0.30734, val loss: 0.36214, in 0.003s\n",
      "[8/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.28166, val loss: 0.34064, in 0.003s\n",
      "[9/5000] 1 tree, 13 leaves, max depth = 7, train loss: 0.25730, val loss: 0.31831, in 0.003s\n",
      "[10/5000] 1 tree, 13 leaves, max depth = 8, train loss: 0.23743, val loss: 0.30332, in 0.003s\n",
      "[11/5000] 1 tree, 13 leaves, max depth = 7, train loss: 0.21805, val loss: 0.28675, in 0.003s\n",
      "[12/5000] 1 tree, 14 leaves, max depth = 9, train loss: 0.20232, val loss: 0.26924, in 0.004s\n",
      "[13/5000] 1 tree, 14 leaves, max depth = 8, train loss: 0.18692, val loss: 0.25670, in 0.003s\n",
      "[14/5000] 1 tree, 13 leaves, max depth = 7, train loss: 0.17328, val loss: 0.24536, in 0.004s\n",
      "[15/5000] 1 tree, 14 leaves, max depth = 9, train loss: 0.16211, val loss: 0.23171, in 0.003s\n",
      "[16/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.14916, val loss: 0.21942, in 0.004s\n",
      "[17/5000] 1 tree, 14 leaves, max depth = 8, train loss: 0.13921, val loss: 0.21116, in 0.003s\n",
      "[18/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.12859, val loss: 0.20068, in 0.003s\n",
      "[19/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.11930, val loss: 0.19466, in 0.003s\n",
      "[20/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.11063, val loss: 0.18783, in 0.004s\n",
      "[21/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.10342, val loss: 0.18227, in 0.003s\n",
      "[22/5000] 1 tree, 14 leaves, max depth = 8, train loss: 0.09623, val loss: 0.17710, in 0.003s\n",
      "[23/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.09031, val loss: 0.17251, in 0.003s\n",
      "[24/5000] 1 tree, 13 leaves, max depth = 7, train loss: 0.08432, val loss: 0.16693, in 0.003s\n",
      "[25/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.07910, val loss: 0.15800, in 0.003s\n",
      "[26/5000] 1 tree, 13 leaves, max depth = 9, train loss: 0.07505, val loss: 0.15397, in 0.003s\n",
      "[27/5000] 1 tree, 14 leaves, max depth = 6, train loss: 0.07016, val loss: 0.14855, in 0.004s\n",
      "[28/5000] 1 tree, 14 leaves, max depth = 6, train loss: 0.06582, val loss: 0.14531, in 0.006s\n",
      "[29/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.06132, val loss: 0.14366, in 0.004s\n",
      "[30/5000] 1 tree, 14 leaves, max depth = 6, train loss: 0.05752, val loss: 0.13957, in 0.003s\n",
      "[31/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.05346, val loss: 0.13875, in 0.003s\n",
      "[32/5000] 1 tree, 13 leaves, max depth = 7, train loss: 0.05015, val loss: 0.13624, in 0.004s\n",
      "[33/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.04674, val loss: 0.13523, in 0.003s\n",
      "[34/5000] 1 tree, 14 leaves, max depth = 6, train loss: 0.04334, val loss: 0.12822, in 0.003s\n",
      "[35/5000] 1 tree, 13 leaves, max depth = 5, train loss: 0.04043, val loss: 0.12536, in 0.003s\n",
      "[36/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.03781, val loss: 0.12648, in 0.003s\n",
      "[37/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.03522, val loss: 0.12474, in 0.003s\n",
      "[38/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.03304, val loss: 0.12512, in 0.003s\n",
      "[39/5000] 1 tree, 12 leaves, max depth = 7, train loss: 0.03075, val loss: 0.12541, in 0.003s\n",
      "[40/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.02803, val loss: 0.12386, in 0.003s\n",
      "[41/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.02600, val loss: 0.12035, in 0.003s\n",
      "[42/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.02378, val loss: 0.11939, in 0.003s\n",
      "[43/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.02182, val loss: 0.11877, in 0.003s\n",
      "[44/5000] 1 tree, 12 leaves, max depth = 5, train loss: 0.02017, val loss: 0.11666, in 0.003s\n",
      "[45/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.01857, val loss: 0.11622, in 0.002s\n",
      "[46/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.01715, val loss: 0.11602, in 0.003s\n",
      "[47/5000] 1 tree, 14 leaves, max depth = 9, train loss: 0.01608, val loss: 0.11492, in 0.003s\n",
      "[48/5000] 1 tree, 13 leaves, max depth = 5, train loss: 0.01479, val loss: 0.11312, in 0.003s\n",
      "[49/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.01368, val loss: 0.11131, in 0.003s\n",
      "[50/5000] 1 tree, 13 leaves, max depth = 5, train loss: 0.01274, val loss: 0.10975, in 0.003s\n",
      "[51/5000] 1 tree, 13 leaves, max depth = 8, train loss: 0.01199, val loss: 0.10905, in 0.002s\n",
      "[52/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.01111, val loss: 0.10964, in 0.002s\n",
      "[53/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.01045, val loss: 0.10634, in 0.004s\n",
      "[54/5000] 1 tree, 12 leaves, max depth = 7, train loss: 0.00982, val loss: 0.10786, in 0.003s\n",
      "[55/5000] 1 tree, 13 leaves, max depth = 7, train loss: 0.00919, val loss: 0.10826, in 0.003s\n",
      "[56/5000] 1 tree, 13 leaves, max depth = 8, train loss: 0.00867, val loss: 0.10862, in 0.003s\n",
      "[57/5000] 1 tree, 13 leaves, max depth = 7, train loss: 0.00809, val loss: 0.10830, in 0.002s\n",
      "[58/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.00753, val loss: 0.10707, in 0.003s\n",
      "[59/5000] 1 tree, 13 leaves, max depth = 5, train loss: 0.00708, val loss: 0.10467, in 0.003s\n",
      "[60/5000] 1 tree, 13 leaves, max depth = 7, train loss: 0.00663, val loss: 0.10320, in 0.003s\n",
      "[61/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.00619, val loss: 0.10087, in 0.003s\n",
      "[62/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.00578, val loss: 0.09954, in 0.003s\n",
      "[63/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.00538, val loss: 0.09810, in 0.003s\n",
      "[64/5000] 1 tree, 13 leaves, max depth = 5, train loss: 0.00498, val loss: 0.10106, in 0.003s\n",
      "[65/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.00469, val loss: 0.10049, in 0.003s\n",
      "[66/5000] 1 tree, 13 leaves, max depth = 7, train loss: 0.00439, val loss: 0.10044, in 0.003s\n",
      "[67/5000] 1 tree, 13 leaves, max depth = 6, train loss: 0.00412, val loss: 0.09856, in 0.003s\n",
      "[68/5000] 1 tree, 13 leaves, max depth = 7, train loss: 0.00389, val loss: 0.10041, in 0.003s\n",
      "[69/5000] 1 tree, 13 leaves, max depth = 7, train loss: 0.00365, val loss: 0.10048, in 0.003s\n",
      "[70/5000] 1 tree, 13 leaves, max depth = 5, train loss: 0.00341, val loss: 0.09885, in 0.003s\n",
      "[71/5000] 1 tree, 13 leaves, max depth = 7, train loss: 0.00323, val loss: 0.10078, in 0.003s\n",
      "[72/5000] 1 tree, 13 leaves, max depth = 7, train loss: 0.00304, val loss: 0.10149, in 0.003s\n",
      "[73/5000] 1 tree, 13 leaves, max depth = 5, train loss: 0.00285, val loss: 0.10203, in 0.003s\n",
      "Fit 73 trees in 0.268 s, (953 total leaves)\n",
      "Time spent computing histograms: 0.043s\n",
      "Time spent finding best splits:  0.050s\n",
      "Time spent applying splits:      0.034s\n",
      "Time spent predicting:           0.003s\n",
      "Train Accuracy:  0.9899497487437185\n",
      "Test Accuracy: 0.9532163742690059\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### permutation_importance\n",
    "특성중요도를 확인하는 함수\n",
    "특정 특성의 데이터를 열단위로 막 섞어서, 모델의 성능이 떨어지면 해당 특성의 중요도를 높이 평가"
   ],
   "id": "39aa5fc52d89eed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:41.503845Z",
     "start_time": "2025-12-22T04:01:41.050927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "perm_importance = permutation_importance(hgb_clf, X_test, y_test, random_state=42, n_jobs=-1, n_repeats=5) # n_jobs : 사용 가능한 모든 CPU 코어 사용\n",
    "                        # n_repeats  : 특정 피처를 몇 번 섞어볼지\n",
    "\n",
    "perm_importance_df = pd.DataFrame({\n",
    "    'Feature' : cancer.feature_names,\n",
    "    'Importance': perm_importance.importances_mean\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "perm_importance_df"
   ],
   "id": "4029af40dc2f2c27",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    Feature    Importance\n",
       "23               worst area  5.263158e-02\n",
       "1              mean texture  1.169591e-02\n",
       "27     worst concave points  8.187135e-03\n",
       "26          worst concavity  8.187135e-03\n",
       "21            worst texture  8.187135e-03\n",
       "4           mean smoothness  7.017544e-03\n",
       "13               area error  7.017544e-03\n",
       "25        worst compactness  5.847953e-03\n",
       "24         worst smoothness  5.847953e-03\n",
       "14         smoothness error  4.678363e-03\n",
       "17     concave points error  3.508772e-03\n",
       "5          mean compactness  3.508772e-03\n",
       "9    mean fractal dimension  3.508772e-03\n",
       "8             mean symmetry  3.508772e-03\n",
       "15        compactness error  3.508772e-03\n",
       "29  worst fractal dimension  3.508772e-03\n",
       "7       mean concave points  1.169591e-03\n",
       "11            texture error  1.169591e-03\n",
       "0               mean radius  1.169591e-03\n",
       "22          worst perimeter  2.220446e-17\n",
       "3                 mean area  0.000000e+00\n",
       "2            mean perimeter  0.000000e+00\n",
       "12          perimeter error  0.000000e+00\n",
       "10             radius error  0.000000e+00\n",
       "6            mean concavity  0.000000e+00\n",
       "16          concavity error  0.000000e+00\n",
       "20             worst radius  0.000000e+00\n",
       "19  fractal dimension error  0.000000e+00\n",
       "18           symmetry error  0.000000e+00\n",
       "28           worst symmetry -2.339181e-03"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>worst area</td>\n",
       "      <td>5.263158e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean texture</td>\n",
       "      <td>1.169591e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>worst concave points</td>\n",
       "      <td>8.187135e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>worst concavity</td>\n",
       "      <td>8.187135e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>worst texture</td>\n",
       "      <td>8.187135e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean smoothness</td>\n",
       "      <td>7.017544e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area error</td>\n",
       "      <td>7.017544e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>worst compactness</td>\n",
       "      <td>5.847953e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>worst smoothness</td>\n",
       "      <td>5.847953e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>smoothness error</td>\n",
       "      <td>4.678363e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points error</td>\n",
       "      <td>3.508772e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean compactness</td>\n",
       "      <td>3.508772e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mean fractal dimension</td>\n",
       "      <td>3.508772e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mean symmetry</td>\n",
       "      <td>3.508772e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness error</td>\n",
       "      <td>3.508772e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>worst fractal dimension</td>\n",
       "      <td>3.508772e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean concave points</td>\n",
       "      <td>1.169591e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture error</td>\n",
       "      <td>1.169591e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean radius</td>\n",
       "      <td>1.169591e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>worst perimeter</td>\n",
       "      <td>2.220446e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean area</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean perimeter</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>perimeter error</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>radius error</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean concavity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity error</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>worst radius</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal dimension error</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry error</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>worst symmetry</td>\n",
       "      <td>-2.339181e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:41.901261Z",
     "start_time": "2025-12-22T04:01:41.583535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sns.barplot(perm_importance_df, x='Importance', y='Feature')\n",
    "plt.show()"
   ],
   "id": "b01814f5ff4af78f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 04.HistGradientBoostingRegressor",
   "id": "9d90f7a3275c0f81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:41.996904Z",
     "start_time": "2025-12-22T04:01:41.982602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ],
   "id": "ca3e2baee76d25c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353, 10) (353,)\n",
      "(89, 10) (89,)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T04:01:42.517335Z",
     "start_time": "2025-12-22T04:01:42.068896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "hgb_reg = HistGradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    max_iter=5000,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=50, # 검증점수가 50번 동안 나아지지 않으면 early_stopping 하겠다.\n",
    "    validation_fraction=0.1,\n",
    "    max_depth=1,\n",
    "    min_samples_leaf=30,\n",
    "    max_bins=255, #기본값 : 255\n",
    "    l2_regularization=0.1, #기본값 : 0, 너무 크게 튀는 것을 막음\n",
    "    learning_rate=0.1, #새로 만든 나무의 예측을 0.1 만큼만 반영하자\n",
    "    verbose=2# 콘솔의 진행상황 출력해라\n",
    "    )\n",
    "\n",
    "\n",
    "hgb_reg.fit(X_train, y_train)\n",
    "print('Train MSE :', mean_squared_error(y_train, hgb_reg.predict(X_train)))\n",
    "print('Train R2 :', r2_score(y_train, hgb_reg.predict(X_train)))\n",
    "\n",
    "print('Test MSE :', mean_squared_error(y_test, hgb_reg.predict(X_test)))\n",
    "print('Test R2 :', r2_score(y_test, hgb_reg.predict(X_test)))\n"
   ],
   "id": "6ae21357d5a9f6fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.000 GB of training data: 0.017 s\n",
      "Binning 0.000 GB of validation data: 0.000 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/5000] 1 tree, 2 leaves, max depth = 1, train loss: 2882.16205, val loss: 2830.32346, in 0.001s\n",
      "[2/5000] 1 tree, 2 leaves, max depth = 1, train loss: 2732.33505, val loss: 2619.59995, in 0.002s\n",
      "[3/5000] 1 tree, 2 leaves, max depth = 1, train loss: 2609.22436, val loss: 2495.90718, in 0.002s\n",
      "[4/5000] 1 tree, 2 leaves, max depth = 1, train loss: 2494.58316, val loss: 2353.15278, in 0.002s\n",
      "[5/5000] 1 tree, 2 leaves, max depth = 1, train loss: 2399.65925, val loss: 2209.30359, in 0.002s\n",
      "[6/5000] 1 tree, 2 leaves, max depth = 1, train loss: 2313.14621, val loss: 2124.42788, in 0.002s\n",
      "[7/5000] 1 tree, 2 leaves, max depth = 1, train loss: 2240.97576, val loss: 2030.96023, in 0.001s\n",
      "[8/5000] 1 tree, 2 leaves, max depth = 1, train loss: 2175.07847, val loss: 1966.26267, in 0.002s\n",
      "[9/5000] 1 tree, 2 leaves, max depth = 1, train loss: 2114.77551, val loss: 1940.08280, in 0.001s\n",
      "[10/5000] 1 tree, 2 leaves, max depth = 1, train loss: 2058.77417, val loss: 1932.22168, in 0.002s\n",
      "[11/5000] 1 tree, 2 leaves, max depth = 1, train loss: 2007.12154, val loss: 1871.31295, in 0.001s\n",
      "[12/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1961.95599, val loss: 1812.90512, in 0.001s\n",
      "[13/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1919.15265, val loss: 1791.59831, in 0.002s\n",
      "[14/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1881.06568, val loss: 1790.97102, in 0.003s\n",
      "[15/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1845.63093, val loss: 1746.44708, in 0.001s\n",
      "[16/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1812.32246, val loss: 1696.49595, in 0.002s\n",
      "[17/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1782.80243, val loss: 1677.03595, in 0.002s\n",
      "[18/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1755.11791, val loss: 1646.44751, in 0.001s\n",
      "[19/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1728.81368, val loss: 1630.71803, in 0.001s\n",
      "[20/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1705.30748, val loss: 1599.07325, in 0.002s\n",
      "[21/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1683.17139, val loss: 1602.69135, in 0.002s\n",
      "[22/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1663.49018, val loss: 1572.47156, in 0.002s\n",
      "[23/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1644.81020, val loss: 1559.56528, in 0.002s\n",
      "[24/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1627.25273, val loss: 1548.68880, in 0.001s\n",
      "[25/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1610.30688, val loss: 1540.04390, in 0.001s\n",
      "[26/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1595.28535, val loss: 1518.53144, in 0.001s\n",
      "[27/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1581.55090, val loss: 1501.76120, in 0.002s\n",
      "[28/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1568.51447, val loss: 1504.87905, in 0.002s\n",
      "[29/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1555.96992, val loss: 1500.75200, in 0.003s\n",
      "[30/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1543.84159, val loss: 1496.54911, in 0.002s\n",
      "[31/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1532.47836, val loss: 1487.19081, in 0.002s\n",
      "[32/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1521.51778, val loss: 1493.06416, in 0.002s\n",
      "[33/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1511.23589, val loss: 1475.81251, in 0.002s\n",
      "[34/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1501.60459, val loss: 1472.06557, in 0.002s\n",
      "[35/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1492.31875, val loss: 1476.72378, in 0.002s\n",
      "[36/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1484.07586, val loss: 1475.43258, in 0.001s\n",
      "[37/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1476.30988, val loss: 1477.54031, in 0.002s\n",
      "[38/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1468.90105, val loss: 1476.92564, in 0.002s\n",
      "[39/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1461.73336, val loss: 1464.01686, in 0.002s\n",
      "[40/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1454.89728, val loss: 1469.28589, in 0.002s\n",
      "[41/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1448.43876, val loss: 1457.18503, in 0.002s\n",
      "[42/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1442.50182, val loss: 1456.56202, in 0.002s\n",
      "[43/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1436.91008, val loss: 1450.00510, in 0.003s\n",
      "[44/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1431.68455, val loss: 1455.57792, in 0.003s\n",
      "[45/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1426.58014, val loss: 1456.48288, in 0.002s\n",
      "[46/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1421.84737, val loss: 1457.71831, in 0.001s\n",
      "[47/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1417.30633, val loss: 1460.08555, in 0.002s\n",
      "[48/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1413.09562, val loss: 1469.24813, in 0.002s\n",
      "[49/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1408.95716, val loss: 1462.89624, in 0.002s\n",
      "[50/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1404.88053, val loss: 1454.45209, in 0.002s\n",
      "[51/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1400.85522, val loss: 1456.26185, in 0.001s\n",
      "[52/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1397.02557, val loss: 1457.99471, in 0.004s\n",
      "[53/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1393.33257, val loss: 1452.08253, in 0.002s\n",
      "[54/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1389.61933, val loss: 1458.05748, in 0.002s\n",
      "[55/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1386.04049, val loss: 1459.84932, in 0.002s\n",
      "[56/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1382.46502, val loss: 1460.26017, in 0.002s\n",
      "[57/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1379.12683, val loss: 1454.67170, in 0.002s\n",
      "[58/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1375.80467, val loss: 1463.25830, in 0.003s\n",
      "[59/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1372.56041, val loss: 1458.54688, in 0.001s\n",
      "[60/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1369.33696, val loss: 1450.42133, in 0.002s\n",
      "[61/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1366.08950, val loss: 1455.71103, in 0.001s\n",
      "[62/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1363.08716, val loss: 1457.49851, in 0.002s\n",
      "[63/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1359.97925, val loss: 1452.31610, in 0.002s\n",
      "[64/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1357.07954, val loss: 1452.90867, in 0.001s\n",
      "[65/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1354.16102, val loss: 1445.30402, in 0.001s\n",
      "[66/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1351.22743, val loss: 1439.34211, in 0.002s\n",
      "[67/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1348.46938, val loss: 1444.88704, in 0.002s\n",
      "[68/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1345.72822, val loss: 1440.25983, in 0.001s\n",
      "[69/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1342.97271, val loss: 1441.01516, in 0.002s\n",
      "[70/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1340.32771, val loss: 1433.84793, in 0.002s\n",
      "[71/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1337.64088, val loss: 1438.87232, in 0.002s\n",
      "[72/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1335.08454, val loss: 1434.27173, in 0.001s\n",
      "[73/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1332.59736, val loss: 1430.02733, in 0.002s\n",
      "[74/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1330.12340, val loss: 1432.42850, in 0.002s\n",
      "[75/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1327.64292, val loss: 1425.58025, in 0.002s\n",
      "[76/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1325.26269, val loss: 1427.48637, in 0.001s\n",
      "[77/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1323.00638, val loss: 1428.95509, in 0.001s\n",
      "[78/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1320.71110, val loss: 1432.31741, in 0.002s\n",
      "[79/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1318.44464, val loss: 1437.62315, in 0.003s\n",
      "[80/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1316.21236, val loss: 1433.74899, in 0.002s\n",
      "[81/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1313.92719, val loss: 1440.86595, in 0.002s\n",
      "[82/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1311.72010, val loss: 1441.50811, in 0.002s\n",
      "[83/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1309.52590, val loss: 1443.28575, in 0.001s\n",
      "[84/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1307.37436, val loss: 1446.54318, in 0.001s\n",
      "[85/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1305.29857, val loss: 1451.19477, in 0.001s\n",
      "[86/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1303.12957, val loss: 1444.70045, in 0.001s\n",
      "[87/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1301.06453, val loss: 1441.13555, in 0.002s\n",
      "[88/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1299.02243, val loss: 1443.00411, in 0.002s\n",
      "[89/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1297.06066, val loss: 1439.21455, in 0.003s\n",
      "[90/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1295.10553, val loss: 1442.54489, in 0.002s\n",
      "[91/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1293.11855, val loss: 1443.28014, in 0.002s\n",
      "[92/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1291.22785, val loss: 1443.92762, in 0.002s\n",
      "[93/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1289.32473, val loss: 1436.13107, in 0.001s\n",
      "[94/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1287.44890, val loss: 1429.21469, in 0.001s\n",
      "[95/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1285.58119, val loss: 1425.93822, in 0.002s\n",
      "[96/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1283.72307, val loss: 1422.15218, in 0.002s\n",
      "[97/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1281.90270, val loss: 1428.46723, in 0.002s\n",
      "[98/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1280.13858, val loss: 1430.85009, in 0.002s\n",
      "[99/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1278.26719, val loss: 1434.11434, in 0.001s\n",
      "[100/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1276.52363, val loss: 1428.55792, in 0.001s\n",
      "[101/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1274.76261, val loss: 1430.50233, in 0.002s\n",
      "[102/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1273.06189, val loss: 1427.54231, in 0.001s\n",
      "[103/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1271.40519, val loss: 1428.15087, in 0.001s\n",
      "[104/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1269.78209, val loss: 1429.22023, in 0.001s\n",
      "[105/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1268.13955, val loss: 1432.44338, in 0.001s\n",
      "[106/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1266.51216, val loss: 1429.19279, in 0.002s\n",
      "[107/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1264.93961, val loss: 1431.58007, in 0.002s\n",
      "[108/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1263.33002, val loss: 1426.34503, in 0.001s\n",
      "[109/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1261.80186, val loss: 1427.93455, in 0.002s\n",
      "[110/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1260.26365, val loss: 1425.22705, in 0.001s\n",
      "[111/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1258.75763, val loss: 1421.95222, in 0.002s\n",
      "[112/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1257.26079, val loss: 1425.85403, in 0.001s\n",
      "[113/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1255.76615, val loss: 1428.96370, in 0.002s\n",
      "[114/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1254.25349, val loss: 1430.84593, in 0.002s\n",
      "[115/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1252.83188, val loss: 1427.65417, in 0.002s\n",
      "[116/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1251.38797, val loss: 1422.70517, in 0.001s\n",
      "[117/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1249.99370, val loss: 1420.29802, in 0.002s\n",
      "[118/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1248.59315, val loss: 1424.28558, in 0.001s\n",
      "[119/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1247.18723, val loss: 1427.43544, in 0.002s\n",
      "[120/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1245.81945, val loss: 1427.16970, in 0.001s\n",
      "[121/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1244.50678, val loss: 1427.71851, in 0.001s\n",
      "[122/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1243.18097, val loss: 1421.48489, in 0.001s\n",
      "[123/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1241.86495, val loss: 1418.22384, in 0.001s\n",
      "[124/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1240.60411, val loss: 1423.41289, in 0.001s\n",
      "[125/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1239.30378, val loss: 1421.17858, in 0.002s\n",
      "[126/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1238.03222, val loss: 1425.57762, in 0.002s\n",
      "[127/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1236.70649, val loss: 1428.67309, in 0.001s\n",
      "[128/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1235.45960, val loss: 1423.27863, in 0.002s\n",
      "[129/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1234.29649, val loss: 1418.99356, in 0.001s\n",
      "[130/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1233.06995, val loss: 1421.23507, in 0.001s\n",
      "[131/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1231.92800, val loss: 1424.24007, in 0.001s\n",
      "[132/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1230.76218, val loss: 1426.04933, in 0.001s\n",
      "[133/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1229.63067, val loss: 1426.62439, in 0.002s\n",
      "[134/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1228.50197, val loss: 1423.71288, in 0.001s\n",
      "[135/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1227.32175, val loss: 1421.71173, in 0.002s\n",
      "[136/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1226.18027, val loss: 1421.59136, in 0.002s\n",
      "[137/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1225.07485, val loss: 1419.25588, in 0.001s\n",
      "[138/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1223.94920, val loss: 1416.87412, in 0.001s\n",
      "[139/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1222.87119, val loss: 1419.77453, in 0.002s\n",
      "[140/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1221.76763, val loss: 1424.65932, in 0.001s\n",
      "[141/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1220.73800, val loss: 1425.34706, in 0.001s\n",
      "[142/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1219.67849, val loss: 1423.48062, in 0.002s\n",
      "[143/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1218.65499, val loss: 1424.83129, in 0.001s\n",
      "[144/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1217.66038, val loss: 1420.91053, in 0.002s\n",
      "[145/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1216.61573, val loss: 1424.45352, in 0.001s\n",
      "[146/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1215.63690, val loss: 1425.46362, in 0.002s\n",
      "[147/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1214.58431, val loss: 1420.00907, in 0.001s\n",
      "[148/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1213.63334, val loss: 1424.04158, in 0.003s\n",
      "[149/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1212.61598, val loss: 1426.84518, in 0.002s\n",
      "[150/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1211.66115, val loss: 1427.37244, in 0.002s\n",
      "[151/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1210.72277, val loss: 1425.67993, in 0.002s\n",
      "[152/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1209.76047, val loss: 1425.72258, in 0.001s\n",
      "[153/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1208.82053, val loss: 1428.90658, in 0.001s\n",
      "[154/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1207.88215, val loss: 1426.38537, in 0.001s\n",
      "[155/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1206.93707, val loss: 1421.27231, in 0.001s\n",
      "[156/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1205.96878, val loss: 1422.30590, in 0.002s\n",
      "[157/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1205.05938, val loss: 1424.93187, in 0.001s\n",
      "[158/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1204.13406, val loss: 1422.90475, in 0.002s\n",
      "[159/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1203.24610, val loss: 1423.27138, in 0.001s\n",
      "[160/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1202.35551, val loss: 1418.35835, in 0.002s\n",
      "[161/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1201.44496, val loss: 1419.38522, in 0.001s\n",
      "[162/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1200.58036, val loss: 1417.78684, in 0.002s\n",
      "[163/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1199.72397, val loss: 1414.26080, in 0.001s\n",
      "[164/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1198.83281, val loss: 1416.30148, in 0.002s\n",
      "[165/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1197.98349, val loss: 1418.90666, in 0.001s\n",
      "[166/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1197.15435, val loss: 1419.36270, in 0.002s\n",
      "[167/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1196.33088, val loss: 1419.53390, in 0.002s\n",
      "[168/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1195.49462, val loss: 1424.16375, in 0.001s\n",
      "[169/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1194.61259, val loss: 1421.39232, in 0.001s\n",
      "[170/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1193.81638, val loss: 1416.83787, in 0.001s\n",
      "[171/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1192.95759, val loss: 1417.80176, in 0.001s\n",
      "[172/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1192.16130, val loss: 1421.94342, in 0.001s\n",
      "[173/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1191.35924, val loss: 1420.47955, in 0.002s\n",
      "[174/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1190.56891, val loss: 1425.00475, in 0.002s\n",
      "[175/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1189.74674, val loss: 1428.94732, in 0.001s\n",
      "[176/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1188.95478, val loss: 1426.70138, in 0.002s\n",
      "[177/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1188.16738, val loss: 1429.17429, in 0.002s\n",
      "[178/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1187.37698, val loss: 1426.57374, in 0.002s\n",
      "[179/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1186.60601, val loss: 1424.72390, in 0.001s\n",
      "[180/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1185.82139, val loss: 1426.66200, in 0.001s\n",
      "[181/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1185.06664, val loss: 1431.12233, in 0.002s\n",
      "[182/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1184.27901, val loss: 1428.95311, in 0.002s\n",
      "[183/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1183.51646, val loss: 1424.49393, in 0.003s\n",
      "[184/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1182.73546, val loss: 1425.46519, in 0.002s\n",
      "[185/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1181.99712, val loss: 1425.90428, in 0.002s\n",
      "[186/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1181.22622, val loss: 1428.33399, in 0.002s\n",
      "[187/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1180.49286, val loss: 1424.44126, in 0.001s\n",
      "[188/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1179.73105, val loss: 1422.66616, in 0.001s\n",
      "[189/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1179.00822, val loss: 1427.04769, in 0.001s\n",
      "[190/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1178.26159, val loss: 1424.49773, in 0.002s\n",
      "[191/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1177.54857, val loss: 1423.19826, in 0.002s\n",
      "[192/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1176.80948, val loss: 1424.32344, in 0.001s\n",
      "[193/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1176.09353, val loss: 1424.08374, in 0.002s\n",
      "[194/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1175.35900, val loss: 1419.75637, in 0.003s\n",
      "[195/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1174.62688, val loss: 1420.73157, in 0.001s\n",
      "[196/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1173.92541, val loss: 1417.69811, in 0.002s\n",
      "[197/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1173.23060, val loss: 1415.92923, in 0.001s\n",
      "[198/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1172.51019, val loss: 1420.31550, in 0.002s\n",
      "[199/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1171.80984, val loss: 1420.49411, in 0.001s\n",
      "[200/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1171.11826, val loss: 1419.23884, in 0.002s\n",
      "[201/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1170.42308, val loss: 1423.04200, in 0.001s\n",
      "[202/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1169.74181, val loss: 1421.40215, in 0.002s\n",
      "[203/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1169.05211, val loss: 1424.29019, in 0.001s\n",
      "[204/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1168.36245, val loss: 1426.65367, in 0.002s\n",
      "[205/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1167.65858, val loss: 1427.32293, in 0.001s\n",
      "[206/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1166.99193, val loss: 1431.57659, in 0.001s\n",
      "[207/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1166.32355, val loss: 1432.53736, in 0.002s\n",
      "[208/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1165.62369, val loss: 1428.32373, in 0.001s\n",
      "[209/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1164.96196, val loss: 1425.91217, in 0.001s\n",
      "[210/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1164.32164, val loss: 1428.20196, in 0.001s\n",
      "[211/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1163.65501, val loss: 1431.86575, in 0.001s\n",
      "[212/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1163.01680, val loss: 1432.82107, in 0.002s\n",
      "[213/5000] 1 tree, 2 leaves, max depth = 1, train loss: 1162.36562, val loss: 1428.79880, in 0.002s\n",
      "Fit 213 trees in 0.412 s, (426 total leaves)\n",
      "Time spent computing histograms: 0.022s\n",
      "Time spent finding best splits:  0.066s\n",
      "Time spent applying splits:      0.024s\n",
      "Time spent predicting:           0.015s\n",
      "Train MSE : 2379.074551661397\n",
      "Train R2 : 0.6084728902587409\n",
      "Test MSE : 2764.018684480001\n",
      "Test R2 : 0.4783051117299759\n"
     ]
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
